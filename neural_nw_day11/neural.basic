# Neural Network - Smart Notes

---

## 1️⃣ Definition

* **Neural Network (NN):** ML/DL model inspired by human brain neurons
* Goal: **Recognize complex patterns**
* Input → Hidden Layers → Output → Loss → Backprop → Weights update

**Trick:** “**NN = Brain-inspired pattern finder**”

---

## 2️⃣ Structure / Flow

```
Input Layer → Hidden Layer(s) → Output Layer
```

* **Input Layer:** Data feed
* **Hidden Layers:** Complex feature extraction (Weighted sum + Activation)
* **Output Layer:** Prediction

**Neuron formula:**

```
output = activation(weight1*x1 + weight2*x2 + ... + bias)
```

---

## 3️⃣ Activation Functions

| Function | Range       | Use Case                                 |
| -------- | ----------- | ---------------------------------------- |
| Sigmoid  | 0–1         | Binary classification                    |
| ReLU     | 0–∞         | Hidden layers (vanishing gradient avoid) |
| Tanh     | -1–1        | Hidden layers                            |
| Softmax  | 0–1 (sum=1) | Multi-class classification               |

**Trick:** “Sigmoid=Yes/No, Softmax=Which class, ReLU=Tackle hidden pain”

---

## 4️⃣ Forward Propagation

1. Input data → Weighted sum
2. Activation → Next layer
3. Repeat till output

**Goal:** generate prediction

---

## 5️⃣ Loss Function

* Measures **prediction vs actual** difference
* Examples:

  * MSE → regression
  * Cross-Entropy → classification

**Trick:** “Loss = Oops meter”

---

## 6️⃣ Backpropagation

* **Weights update** to minimize loss
* Formula:

```
weight_new = weight_old - learning_rate * gradient
```

* Repeat for epochs → model trains

**Trick:** “NN learns by correcting its mistakes”

---

## 7️⃣ Supervised vs Unsupervised in NN

| Type         | Labels | NN Example            | Use Case                      |
| ------------ | ------ | --------------------- | ----------------------------- |
| Supervised   | Yes    | Normal NN             | Classification, Regression    |
| Unsupervised | No     | Autoencoder, GAN, SOM | Clustering, Anomaly detection |

**Trick:** “Label = Supervised, No label = Self-learning / Unsupervised”

---

## 8️⃣ Real-Life Use Cases

* Image Recognition → Face ID, Cat/Dog classifier
* NLP → Chatbots, Translation
* Finance → Stock price, Fraud detection
* Healthcare → Disease prediction

**Trick:** “NN = Brain for images, text, money, health”

---

## ✅ Quick Flow Summary

```
Input Data
   ↓
Hidden Layers (weights + activation)
   ↓
Output Layer (prediction)
   ↓
Loss Function (compare with actual)
   ↓
Backpropagation (update weights)
   ↓
Repeat till model is trained
```

