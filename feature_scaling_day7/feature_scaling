üìÇ **Day 10: Feature Scaling ‚Äì Smart Notes**

---

# 1Ô∏è‚É£ Feature Scaling ‚Äì Why?

* ML models sensitive to **different ranges** of features.
* Example: Age (10-80), Income (10k-1M), Rating (1-5).
* Without scaling, large ranges dominate.

**Trick:** "Resize or center features so model treats them equally."

---

# 2Ô∏è‚É£ Popular Scalers

## a) MinMaxScaler ‚Äì "Resize to 0-1"

* Formula: X_scaled = (X - X_min)/(X_max - X_min)
* Result: Features in range [0,1]
* Use Case: Neural Networks, KNN

**Example:**
Maths Marks = [50, 90], Sports = [2, 8]

* Maths: (90-50)/(90-50) = 1, (50-50)/40 = 0
* Sports: (8-2)/(8-2) = 1, (2-2)/6 = 0
* ‚úÖ Both features equally weighted now

**Trick:** "MinMaxScaler = Resize to 0-1"

## b) StandardScaler ‚Äì "Mean 0, Std 1"

* Formula: X_scaled = (X - mean)/std
* std = standard deviation (sample: divide by N-1)
* Result: Centered around 0, std deviation = 1
* Use Case: Linear regression, Logistic regression, SVM, Neural Networks

**Example:**
Maths = [50, 90], mean=70, std‚âà28.28 (sample std)

* A: (90-70)/28.28 ‚âà 0.71
* B: (50-70)/28.28 ‚âà -0.71
  Sports = [2, 8], mean=5, std‚âà2.83
* A: (8-5)/2.83 ‚âà 1.06
* B: (2-5)/2.83 ‚âà -1.06

**Trick:** "StandardScaler = Center around 0"

---

# 3Ô∏è‚É£ Standard Deviation Quick Calculation

* Formula: std = sqrt(sum((X_i - mean)^2)/(N-1))  # Sample std
* Steps:

  1. Find mean
  2. Subtract mean from each value
  3. Square each difference
  4. Sum all squares
  5. Divide by N-1 (sample) or N (population)
  6. Take sqrt

**Trick:** "Std = Average distance from mean, then sqrt"

---

# 4Ô∏è‚É£ Feature Scaling Flow ‚Äì Smart View

1. Check feature ranges
2. If large differences ‚Üí scale
3. Decide scaler:

   * Neural Networks/KNN ‚Üí MinMaxScaler
   * Linear models/SVM ‚Üí StandardScaler
4. Apply scaler ‚Üí transformed features
5. Train ML model with scaled features

---

# 5Ô∏è‚É£ Quick Real Life Trick

* Think **MinMaxScaler = Resize to 0-1**
* Think **StandardScaler = Mean 0, Std 1**
* Small numbers don't get ignored, big numbers don't dominate

---

# ‚úÖ Summary

* Always scale features when ranges differ
* Know when to use MinMax vs Standard
* StandardScaler uses sample std by default in Python
* MinMaxScaler keeps features between 0 and 1

